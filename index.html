<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<title>Ziggeo Test Video Page</title>
	<link rel="stylesheet" href="https://assets-cdn.ziggeo.com/v1-stable/ziggeo.css" />
  <script
  src="https://code.jquery.com/jquery-3.2.0.slim.min.js"
  integrity="sha256-qLAv0kBAihcHZLI3fv3WITKeRsUX27hd6upBBa0MSow="
  crossorigin="anonymous"></script>
	<script src="https://assets-cdn.ziggeo.com/v1-stable/ziggeo.js"></script>
  <!-- <script src="chromeSpeechLog.js"></script> -->
	<script>ZiggeoApi.token = "a57eb696426aa86a891d1bb9baa0b9ab";</script>
	<script>ZiggeoApi.Config.webrtc = true;</script> 
	
</head>
<body>
	<ziggeo ziggeo-meta_profile="6d7323ec4979d8d5b4bca6eb9ab1c695"
          ziggeo-width=320
          ziggeo-height=240>
  </ziggeo>

  <button onclick="startButton(event);">Audio Record</button>

  <div id="transcription-output-area">
    
  </div>
  <div id="insights">
    
  </div>
</body>

<!-- Alert when video finished recording -->
<script>
ZiggeoApi.Events.on("submitted", function (data) {
    alert("The video with token " + data.video.token + " has been submitted!");
});
</script>

<!-- Play videos code -->
<script>
    ZiggeoApi.Videos.source('')
</script>

<!-- Use Javascript on the client-side to dynamically display videos using e.g. JQuery. -->

<script>
    ZiggeoApi.Videos.index({}, {
        success: function (args, videos) {
            for (var i = 0; i < videos.length; ++i)
                $("body").append("<ziggeo ziggeo-video='" + videos[i].token + "'></ziggeo>");
        }
    });
</script>

<script>

// Personality Insights
// ==============================================================================



// // Speech Logger
// ==============================================================================
  if (!('webkitSpeechRecognition' in window)) {
    //Speech API not supported here…
    alert("Speech Logger not available, try using Google Chrome");
} else { //Let’s do some cool stuff :)
    var recognition = new webkitSpeechRecognition(); //That is the object that will manage our whole recognition process. 
    recognition.continuous = true;   //Suitable for dictation. 
    recognition.interimResults = true;  //If we want to start receiving results even if they are not final.
    //Define some more additional parameters for the recognition:
    recognition.lang = "en-US"; 
    recognition.maxAlternatives = 1; //Since from our experience, the highest result is really the best...
}

recognition.onstart = function() {
    //Listening (capturing voice from audio input) started.
    //This is a good place to give the user visual feedback about that (i.e. flash a red light, etc.)
    console.log('record start');
    $('#transcription-output-area').css('background-color', 'yellow');

};

recognition.onend = function() {
    //Again – give the user feedback that you are not listening anymore. If you wish to achieve continuous recognition – you can write a script to start the recognizer again here.
    $('#transcription-output-area').css('background-color', 'green');
};

recognition.onresult = function(event) { //the event holds the results
//Yay – we have results! Let’s check if they are defined and if final or not:
    if (typeof(event.results) === 'undefined') { //Something is wrong…
        recognition.stop();
        return;
    }

    for (var i = event.resultIndex; i < event.results.length; ++i) {      
        if (event.results[i].isFinal) { //Final results
            console.log("final results: " + event.results[i][0].transcript);   //Of course – here is the place to do useful things with the results.
            $('#transcription-output-area').html('' + event.results[i][0].transcript);
            inputText = event.results[i][0].transcript;

            $.post('/findInsight', inputText).done(function(data) {
              $('#insights').html("" + data);
            });

        } else {   //i.e. interim...
            console.log("interim results: " + event.results[i][0].transcript);  //You can use these results to give the user near real time experience.
            $('#transcription-output-area').append('' + event.results[i][0].transcript);
        } 
    } //end for loop
}; 

function startButton(event) {
    recognition.start();
    // start_img.src = 'https://speechlogger.appspot.com/images/micslash2.png'; //We change the image to a slashed until the user approves the browser to listen and recognition actually starts. Then – we’ll change the image to ‘mic on’.
}
</script>
</html>